{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"GBQ - 1.0.2","text":""},{"location":"#example","title":"Example","text":"<pre><code>from gbq import BigQuery\n\n# BigQuery project id as listed in the Google Developers Console.\nproject_id = 'project_id'\n\n# BigQuery dataset id as listed in the Google Developers Console.\ndataset_id = 'dataset_id'\n\n# BigQuery table/view id as listed in the Google Developers Console.\nstructure_id = 'structure_id'\n\n# BigQuery structure definition as defined in the Google Developers Console.\njson_schema = {\"type\": \"table\", \"schema\": [{\"id\": \"integer\"}]}\n\n# Service account email address as listed in the Google Developers Console.\nsvc_account = '{\"type\": \"service_account\",   \"project_id\": \"project_id\"}'\n\nbq = BigQuery(svc_account=svc_account, project=project_id)\n\nbq.create_or_update_structure(project_id, dataset_id, structure_id, json_schema)\n</code></pre>"},{"location":"#where-to-start","title":"Where to Start?","text":"<p>To learn the basics of how to start using <code>gbq</code>, read the Getting Started page.</p>"},{"location":"#detailed-documentation","title":"Detailed Documentation","text":"<p>To learn more about the various ways <code>gbq</code> can be used, read the Usage Guide page.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>../CHANGELOG.md</p>"},{"location":"development-guide/","title":"Development Guide","text":"<p>Welcome! Thank you for wanting to make the project better. This section provides an overview on how repository structure and how to work with the code base.</p> <p>Before you dive into this, it is best to read:</p> <ul> <li>The Code of Conduct</li> <li>The Contributing guide</li> </ul>"},{"location":"development-guide/#docker","title":"Docker","text":"<p>The GBQ project uses Docker to ease setting up a consistent development environment. The Docker documentation has details on how to install docker on your computer.</p> <p>Once that is configured, the test suite can be run locally:</p> <pre><code>docker-compose run --rm test\n</code></pre> <p>If you want to be able to execute code in the container:</p> <pre><code>docker-compose run --rm devbox\n(your code here)\n</code></pre> <p>In the devbox environment you'll be able to enter a python shell and import <code>gbq</code> or any dependencies.</p>"},{"location":"development-guide/#debugging","title":"Debugging","text":"<p>The docker container has pdb++ install that can be used as a debugger. (However, you are welcome to set up a different debugger if you would like.)</p> <p>This allows you to easily create a breakpoint anywhere in the code.</p> <pre><code>def my_function():\n    breakpoint()\n    ...\n</code></pre> <p>When your the code, you will drop into an interactive <code>pdb++</code> debugger.</p> <p>See the documentation on pdb and pdb++ for more information.</p>"},{"location":"development-guide/#testing","title":"Testing","text":"<p>You'll be unable to merge code unless the linting and tests pass. You can run these in your container via:</p> <pre><code>docker-compose run --rm test\n</code></pre> <p>This will run the same tests, linting, and code coverage that are run by the CI pipeline. The only difference is that, when run locally, <code>black</code> and <code>isort</code> are configured to automatically correct issues they detect.</p> <p>Generally we should endeavor to write tests for every feature. Every new feature branch should increase the test coverage rather than decreasing it.</p> <p>We use pytest as our testing framework.</p>"},{"location":"development-guide/#stages","title":"Stages","text":"<p>To customize / override a specific testing stage, please read the documentation specific to that tool:</p> <ol> <li>PyTest</li> <li>MyPy</li> <li>Black</li> <li>Isort</li> <li>Flake8</li> <li>Bandit</li> </ol>"},{"location":"development-guide/#building-the-library","title":"Building the Library","text":"<p><code>gbq</code> is PEP 517 compliant. build is used as the frontend tool for building the library. Setuptools is used as the build backend. <code>setup.cfg</code> contains the library metadata. A <code>setup.py</code> is also included to support an editable install.</p>"},{"location":"development-guide/#requirements","title":"Requirements","text":"<ul> <li>requirements.lock - Lists all direct dependencies (packages imported by the library).</li> <li>requirements-test.txt - Lists all direct dependencies needed for development. This primarily covers dependencies needed to run the test suite &amp; lints.</li> </ul>"},{"location":"development-guide/#publishing-a-new-version","title":"Publishing a New Version","text":"<p>Once the package is ready to be released, there are a few things that need to be done:</p> <ol> <li>Start with a local clone of the repo on the default branch with a clean working tree.</li> <li> <p>Run the version bump script with the appropriate part name (<code>major</code>, <code>minor</code>, or <code>patch</code>).     Example: <code>docker-compose run --rm bump minor</code></p> <p>This wil create a new branch, updates all affected files with the new version, and commit the changes to the branch.</p> </li> <li> <p>Push the new branch to create a new pull request.</p> </li> <li>Get the pull request approved.</li> <li>Merge the pull request to the default branch.</li> </ol> <p>Merging the pull request will trigger a GitHub Action that will create a new release. The creation of this new release will trigger a GitHub Action that will to build a wheel &amp; a source distributions of the package and push them to PyPI.</p> <p>Warning</p> <p>The action that uploads the files to PyPI will not run until a repository maintainer acknowledges that the job is ready to run. This is to keep the PyPI publishing token secure. Otherwise, any job would have access to the token. </p> <p>In addition to uploading the files to PyPI, the documentation website will be updated to include the new version. If the new version is a full release, it will be made the new <code>latest</code> version.</p>"},{"location":"development-guide/#continuous-integration-pipeline","title":"Continuous Integration Pipeline","text":"<p>The Continuous Integration (CI) Pipeline runs to confirm that the repository is in a good state. It will run when  someone creates a pull request or when they push new commits to the branch for an existing pull request. The pipeline runs multiple different jobs that helps verify the state of the code.</p> <p>This same pipeline also runs on the default branch when a maintainer merges a pull request.</p>"},{"location":"development-guide/#lints","title":"Lints","text":"<p>The first set of jobs that run as part of the CI pipline are linters that perform static analysis on the code. This includes: MyPy, Black, Isort, Flake8, and Bandit.</p>"},{"location":"development-guide/#tests","title":"Tests","text":"<p>The next set of jobs run the unit tests using PyTest. The pipeline runs the tests cases across each supported version of Python to ensure compatibility.</p> <p>For each run of the test cases, the job will record the test results and code coverage information. The pipeline uploads the code coverage information to CodeCov to ensure that a pull request doesn't significantly reduce the total code coverage percentage or introduce a large amount of code that is untested.</p>"},{"location":"development-guide/#distribution-verification","title":"Distribution Verification","text":"<p>The next set of jobs build the wheel distribution, installs in into a virtual environment, and then runs Python to import the library version. This works as a smoke test to ensure that the library can be packaged correctly and used. The pipeline runs the tests cases across each supported version of Python to ensure compatibility.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<p>To install <code>gbq</code>, simply run this simple command in your terminal of choice:</p> <pre><code>python -m pip install gbq\n</code></pre>"},{"location":"getting-started/#introduction","title":"Introduction","text":"<p><code>gbq</code> was developed internally at Wayfair to be used a CD pipeline to create/update tables on Google BigQuery.</p> <p>At Wayfair <code>gbq</code> is used in a with a BigQuery plugin which reads <code>json</code> schema files and updates the schemas on Google BigQuery.</p>"},{"location":"getting-started/#whats-next","title":"What's Next?","text":"<p>TODO</p>"}]}